#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´ç”Ÿæˆå™¨å‘½ä»¤è¡Œè„šæœ¬
"""

import os
import logging
from novel_generator import (
    Novel_architecture_generate,
    Chapter_blueprint_generate,
    generate_chapter_draft,
    finalize_chapter
)
from character_summary import update_character_state_file
from database.config_manager import set_monitoring_enabled

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('novel_generation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# APIé…ç½®
#interface_format = "qwen"  
#api_key = "sk-1ef165b563f646a482c2a0b589fa9b09" 
#base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"  
#model_name = "qwen3-235b-a22b-thinking-2507"  
# max_tokens = 32768   # qwen3

#interface_format = "doubao"
#api_key = "141c1a18-56d4-4799-a975-44585266f86c"
#base_url = "https://ark.cn-beijing.volces.com/api/v3"
#model_name = "doubao-seed-1-6-flash-250715"
# max_tokens = 32000  # doubao

#topic = """é¡¶æµç”·æ˜æ˜Ÿä¸æ‰åæ¨ªæº¢ä½†ä½è°ƒçš„å¥³ç¼–å‰§å› å·¥ä½œç›¸çŸ¥ç›¸æƒœï¼Œå‘å±•ä¸ºéšç§˜çš„åœ°ä¸‹æ‹æƒ…ã€‚æ‹æƒ…æ„å¤–è¢«ç‹—ä»”æ›å…‰ï¼Œå¼•å‘è½©ç„¶å¤§æ³¢ã€‚ç”·ä¸»é­é‡ç²‰ä¸æµå¤±ã€äº‹ä¸šé‡åˆ›ï¼Œå¥³ä¸»æ‰¿å—å·¨å¤§èˆ†è®ºå‹åŠ›æ¿’ä¸´å´©æºƒã€‚åŒä¸ºé¡¶æµçš„å¥³äºŒçœ‹å‡†æ—¶æœºï¼Œè¯•å›¾åˆ©ç”¨è‡ªèº«èµ„æºä¹˜è™šè€Œå…¥ï¼Œä»‹å…¥ä¸¤äººå…³ç³»ã€‚é¢å¯¹äº‹ä¸šå´©ç›˜å’Œå¤–ç•Œè¯±æƒ‘ï¼Œç”·å¥³ä¸»é€‰æ‹©åšå®ˆå½¼æ­¤ï¼Œå…±åŒæŠµæŠ—å‹åŠ›ã€‚â€‹â€‹ ä¸¤äººå…±åŒé¢å¯¹èˆ†è®ºï¼Œç”·ä¸»è½¬å‹ï¼Œå¥³ä¸»ç”¨å®åŠ›è¯æ˜è‡ªå·±ï¼Œæœ€ç»ˆèµ°å‡ºä½è°·ï¼Œäº‹ä¸šçˆ±æƒ…åŒä¸°æ”¶ã€‚"""
#topic = "é¡¶æµç”·æ­Œæ‰‹æ±Ÿæ¥ ä¸ºé€ƒé¿ç»çºªäººå®‰æ’çš„ç‚’ä½œï¼Œèº²è¿›ä¸€å®¶èŠ±åº—ï¼Œé‡åˆ°äº†å®‰é™çš„èŠ±è‰ºå¸ˆå‘¨æ™´ã€‚ä¸¤äººåœ¨èŠ±é¦™ä¸­ç›¸æ‹ï¼Œä½†æ±Ÿæ¥ çš„å‰å¥³å‹â€”â€”åŒæ ·æ˜¯æ˜æ˜Ÿçš„è®¸é›…â€”â€”å‘ç°äº†è¿™æ®µæ„Ÿæƒ…ï¼Œæ•…æ„æ³„éœ²ç»™åª’ä½“ã€‚èˆ†è®ºé£æš´ä¸­ï¼Œå‘¨æ™´çš„èŠ±åº—è¢«ç²‰ä¸å›´å µï¼Œå¥¹ä¸å ªé‡è´Ÿé€‰æ‹©ç¦»å¼€ã€‚æ±Ÿæ¥ åœ¨æ¼”å”±ä¼šä¸Šå…¬å¼€è¡¨ç™½ï¼Œç”¨ä¸€é¦–ä¸ºå‘¨æ™´å†™çš„æ­ŒæŒ½å›çˆ±æƒ…ã€‚"
#topic = "é«˜å†·å¥³å¾‹å¸ˆä¸ºäº†åœ¨å®¶æ—èšä¼šä¸­æ‘†è„±å‚¬å©šï¼Œä¸´æ—¶é›‡ä½£å’–å•¡åº—æœåŠ¡å‘˜å‡æ‰®ç”·å‹ã€‚æ²¡æƒ³åˆ°è¿™ä¸ªçœ‹ä¼¼æ™®é€šçš„æœåŠ¡å‘˜ç«Ÿæ˜¯éšè—èº«ä»½çš„ç§‘æŠ€å…¬å¸ç»§æ‰¿äººï¼Œä¸¤äººåœ¨ä¸€æ¬¡æ¬¡æ¼”æˆä¸­å‡æˆçœŸåšã€‚"
#topic = "ç”·ä¸»è¿½æ±‚å¥³ä¸»ï¼Œä½†å¥³ä¸»çœ‹ä¸èµ·ç”·ä¸»ï¼Œå¸¸å¸¸åœ¨ç”·ä¸»é¢å‰ä¸ç”·äºŒåšäº²å¯†åŠ¨ä½œï¼Œç”·ä¸»å³ä¼¤å¿ƒåˆæ„¤æ€’ï¼Œå´åˆæ— å¯å¥ˆä½•ï¼Œçªç„¶æœ‰ä¸€å¤©ç”·ä¸»è·å¾—äº†è¶…èƒ½åŠ›ï¼Œå¸å¼•äº†å¥³ä¸»çš„æ³¨æ„ï¼Œå¥³ä¸»å¼€å§‹è¿½æ±‚ç”·ä¸»ï¼ŒåŒæ—¶ä¹Ÿæœ‰å…¶å®ƒå¥³ç”Ÿè¿½æ±‚ç”·ä¸»ã€‚åè½¬ï¼šå¥³ä¸»ç”±äºçˆ¶äº²è´Ÿå€ºè¢«è¿«ä¸ç”·äºŒåœ¨ä¸€èµ·"


async def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºå®Œæ•´çš„å°è¯´ç”Ÿæˆæµç¨‹
    """
    
    # å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ§åˆ¶ç›‘æ§åŠŸèƒ½çš„å¼€å¯/å…³é—­
    set_monitoring_enabled(True)   # å¼€å¯ç›‘æ§
    # set_monitoring_enabled(False)  # å…³é—­ç›‘æ§

    # ==================== é…ç½®å‚æ•° ====================
    interface_format = 'gemini'
    # api_key ="AIzaSyD36taFUaT7sv0iKwzLyuFeqZiZPoQtSnA" # è‡ªå·±çš„
    # api_key = "AIzaSyBCaevYiLbu8kE5VdPYZA8w8mUCWX9zwZA"  # è´­ä¹°1
    api_key = "AIzaSyB-AwMVI5PYGihROiUME3DOz7_lkk0Tovw"  # è´­ä¹°2

    base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
    model_name1 = "gemini-2.5-flash"   # æ›´æ–°è§’è‰²å’Œæ€»ç»“è§’è‰²
    model_name2 = "gemini-2.5-pro"   # å°è¯´æ¶æ„ï¼Œç« èŠ‚ç›®å½•å’Œç« èŠ‚æ­£æ–‡
    
    # ç”Ÿæˆå‚æ•°
    temperature1 = 0.7     # å°è¯´æ¶æ„å’Œç« èŠ‚å†…å®¹
    temperature2 = 0.1     # ç« èŠ‚ç›®å½•ã€æ›´æ–°è§’è‰²çŠ¶æ€å’Œæ€»ç»“è§’è‰²çŠ¶æ€
    temperature3 = 1.3     # å•ç‹¬æ§åˆ¶å°è¯´å‰§æƒ…
    max_tokens = 65536            # geminiæœ€å¤§è¾“å‡ºtoken
    timeout = 600


    # å°è¯´åŸºæœ¬è®¾ç½®
    topic = "å‡ºèº«å¹³å‡¡çš„ç”·ç”Ÿå§‹ç»ˆå€¾æ…•ç€å®¶å¢ƒä¼˜æ¸¥ã€æ°”è´¨å‡ºä¼—çš„å¥³å­©ï¼Œå´å› ä¸¤äººä¹‹é—´æ‚¬æ®Šçš„å·®è·ï¼Œè¿é è¿‘çš„æœºä¼šéƒ½å¯¥å¯¥æ— å‡ ï¼Œè¿™ä»½å¿ƒæ„åªèƒ½æ·±åŸ‹å¿ƒåº•ã€‚ä¸€æ¬¡å¶ç„¶çš„å–„ä¸¾ï¼Œä»–æ•‘åŠ©äº†ä¸€ä½é™·å…¥å›°å¢ƒçš„è€äººï¼Œæ„å¤–è·å¾—äº†è¶³ä»¥æ”¹å†™å¢ƒé‡çš„è¶…èƒ½åŠ›ã€‚å‡­å€Ÿè¿™ä»½ â€œé¦ˆèµ â€ï¼Œä»–åœ¨ä¼—å¤šå®¶å¢ƒä¼˜è¶Šã€æ¡ä»¶å‡ºä¼—çš„è¿½æ±‚è€…ä¸­è„±é¢–è€Œå‡ºï¼Œä¸ä»…æ‰“ç ´äº†æ›¾ç»çš„å·®è·å£å’ï¼Œæ›´æˆåŠŸæ‰“åŠ¨å¥³å­©ï¼Œèµ¢å¾—äº†å¥¹çš„é’çã€‚å°±åœ¨ä¸¤äººæ„Ÿæƒ…é€æ¸å‡æ¸©ï¼Œä»–ä»¥ä¸ºç»ˆäºæŠ“ä½å¹¸ç¦æ—¶ï¼Œè¶…èƒ½åŠ›å´æ¯«æ— å¾å…†åœ°çªç„¶æ¶ˆå¤±ã€‚æ›¾ç»é è¶…èƒ½åŠ›æ­å»ºçš„ä¼˜åŠ¿ç¬é—´å´©å¡Œï¼Œä»–ä¸å¾—ä¸é¢å¯¹ä¸€ä¸ªæ®‹é…·çš„é—®é¢˜ï¼šå¤±å» â€œå¤–æŒ‚â€ çš„è‡ªå·±ï¼Œè¿˜èƒ½ç•™ä½è¿™ä»½æ¥ä¹‹ä¸æ˜“çš„çˆ±æƒ…å—ï¼Ÿ"
    # topic = "å¥³ä¸»æ›¾æ˜¯å®¶å¢ƒä¼˜æ¸¥çš„åƒé‡‘ï¼Œå´å› å®¶æ—ä¼ä¸šç ´äº§è€Œè·Œå…¥è°·åº•ã€‚å¥¹ä¸å¾—ä¸ä»é›¶å¼€å§‹ï¼Œè¿›å…¥èŒåœºï¼Œä¸ç”·ä¸»ï¼Œä¸€ä½æ›¾ç»è¢«å¥¹çœ‹ä¸èµ·çš„æ™®é€šèŒå‘˜ï¼Œå†æ¬¡ç›¸é‡ã€‚ç”·ä¸»é»˜é»˜å¸®åŠ©å¥¹ï¼Œå¥³ä¸»ä¹Ÿå‡­å€Ÿè‡ªå·±çš„åŠªåŠ›å’Œæ™ºæ…§ï¼Œä¸€æ­¥æ­¥é‡æŒ¯å®¶æ—ã€‚"
    genre = "éƒ½å¸‚è¨€æƒ…"
    number_of_chapters = 100       # æ€»ç« èŠ‚æ•°
    word_number = 1200             # æ¯ç« å­—æ•°ï¼ˆå°è¯´è¦æ±‚æ¯ç« è‡³å°‘1200å­—ï¼‰
    chunk_size = 25                # ç« èŠ‚ç›®å½•ç”Ÿæˆæ—¶ï¼Œæ¯æ¬¡ç”Ÿæˆå¤šå°‘ç« èŠ‚
    limit_chapters = 25            # æ¯æ¬¡ç”Ÿæˆç« èŠ‚æ—¶ï¼Œæä¾›å¤šå°‘ç« å·²ç»ç”Ÿæˆå¥½çš„ç« èŠ‚ä¿¡æ¯

    # ç”¨æˆ·æŒ‡å¯¼ï¼ˆå¯é€‰ï¼‰
    user_guidance = "æ•…äº‹æƒ…èŠ‚è¦ä¸°å¯Œï¼Œå¾ªåºæ¸è¿›åœ°æ¨è¿›å‰§æƒ…ã€‚å™è¿°æ‰‹æ³•å¤šæ ·åŒ–ã€‚äººç‰©çš„èƒŒæ™¯ä¸è¦ä¸€å¼€å§‹å°±å…¨ç›˜æ‰˜å‡ºï¼Œè€Œæ˜¯è¦éšç€å‰§æƒ…çš„å±•å¼€é€æ­¥æ­ç¤ºã€‚åœ¨å‰§æƒ…éœ€è¦æ—¶ï¼Œå¯ä»¥åŠ å…¥æ–°çš„è§’è‰²ã€‚"
    
    # æ–‡ä»¶ä¿å­˜è·¯å¾„
    filepath = "./Novel_Output"  # å°è¯´è¾“å‡ºç›®å½•
    
    # ==================== å¼€å§‹ç”Ÿæˆæµç¨‹ ====================
    
    print("=" * 60)
    print("ğŸš€ å¼€å§‹å°è¯´ç”Ÿæˆæµç¨‹")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(filepath, exist_ok=True)
    
    try:
        '''
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå°è¯´æ¶æ„
        print("\nğŸ“‹ ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå°è¯´æ¶æ„...")
        Novel_architecture_generate(
            interface_format=interface_format,
            api_key=api_key,
            base_url=base_url,
            llm_model=model_name2,
            topic=topic,
            genre=genre,
            number_of_chapters=number_of_chapters,
            word_number=word_number,
            filepath=filepath,
            user_guidance=user_guidance,
            temperature=temperature1,
            temperature_plot=temperature3,
            max_tokens=max_tokens,
            timeout=timeout
        )
        print("âœ… å°è¯´æ¶æ„ç”Ÿæˆå®Œæˆï¼")

        # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆç« èŠ‚è“å›¾
        print("\nğŸ“– ç¬¬äºŒæ­¥ï¼šç”Ÿæˆç« èŠ‚è“å›¾...")
        Chapter_blueprint_generate(
            interface_format=interface_format,
            api_key=api_key,
            base_url=base_url,
            llm_model=model_name2,
            filepath=filepath,
            number_of_chapters=number_of_chapters,
            temperature=temperature2,
            max_tokens=max_tokens,
            chunk_size=chunk_size,
            limit_chapters=limit_chapters,
            timeout=timeout
        )
        print("âœ… ç« èŠ‚è“å›¾ç”Ÿæˆå®Œæˆï¼")
        '''

        # ç¬¬ä¸‰æ­¥ï¼šé€ç« ç”Ÿæˆå†…å®¹
        print("\nâœï¸ ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹ç”Ÿæˆç« èŠ‚å†…å®¹...")
        for chapter_num in range(31, number_of_chapters + 1):
            print(f"\n--- æ­£åœ¨ç”Ÿæˆç¬¬ {chapter_num} ç«  ---")

            # ç”Ÿæˆç« èŠ‚è‰ç¨¿
            draft_content = generate_chapter_draft(
                api_key=api_key,
                base_url=base_url,
                model_name=model_name2,
                filepath=filepath,
                novel_number=chapter_num,
                word_number=word_number,
                temperature=temperature1,
                user_guidance=user_guidance,
                interface_format=interface_format,
                max_tokens=max_tokens,
                genre=genre,
                timeout=timeout
            )
            
            if draft_content:
                print(f"âœ… ç¬¬ {chapter_num} ç« è‰ç¨¿ç”Ÿæˆå®Œæˆï¼")
                
                # å®šç¨¿ç« èŠ‚
                print(f"ğŸ¯ æ­£åœ¨å®šç¨¿ç¬¬ {chapter_num} ç« ...")
                await finalize_chapter(
                    novel_number=chapter_num,
                    api_key=api_key,
                    base_url=base_url,
                    model_name=model_name1,
                    temperature=temperature2,
                    filepath=filepath,
                    interface_format=interface_format,
                    max_tokens=max_tokens,
                    timeout=timeout
                )
                print(f"âœ… ç¬¬ {chapter_num} ç« å®šç¨¿å®Œæˆï¼")
                
                # æ¯äº”ç« è¿›è¡Œè§’è‰²çŠ¶æ€æ€»ç»“
                if chapter_num % 10 == 0:
                    print(f"\nğŸ”„ æ­£åœ¨å¯¹å‰ {chapter_num} ç« è¿›è¡Œè§’è‰²çŠ¶æ€æ€»ç»“...")
                    try:
                        update_character_state_file(
                            filepath=filepath,
                            interface_format=interface_format,
                            api_key=api_key,
                            base_url=base_url,
                            model_name=model_name1,
                            chapter_num=chapter_num,
                            temperature=temperature2,
                            max_tokens=max_tokens,
                            timeout=timeout
                        )
                        print(f"âœ… ç¬¬ {chapter_num} ç« è§’è‰²çŠ¶æ€æ€»ç»“å®Œæˆï¼")
                        break
                        '''
                        # ä¿å­˜global_summaryå¤‡ä»½æ–‡ä»¶
                        print(f"ğŸ“ æ­£åœ¨ä¿å­˜ç¬¬ {chapter_num} ç« global_summaryå¤‡ä»½...")
                        try:
                            global_summary_file = os.path.join(filepath, "global_summary.txt")
                            if os.path.exists(global_summary_file):
                                # è¯»å–å½“å‰global_summaryå†…å®¹
                                global_summary_content = read_file(global_summary_file)
                                
                                # ä¿å­˜å¤‡ä»½æ–‡ä»¶
                                backup_filename = f"global_summary{chapter_num}.txt"
                                backup_file_path = os.path.join(filepath, backup_filename)
                                save_string_to_txt(global_summary_content, backup_file_path)
                                print(f"âœ… å·²ä¿å­˜ç¬¬{chapter_num}ç« global_summaryå¤‡ä»½æ–‡ä»¶: {backup_filename}")
                            else:
                                print(f"âš ï¸ global_summary.txtæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
                        except Exception as backup_error:
                            print(f"âš ï¸ global_summaryå¤‡ä»½å¤±è´¥ï¼š{str(backup_error)}")
                            logging.error(f"global_summaryå¤‡ä»½é”™è¯¯ï¼š{str(backup_error)}", exc_info=True)
                        '''
                    except Exception as e:
                        print(f"âš ï¸ è§’è‰²çŠ¶æ€æ€»ç»“å¤±è´¥ï¼š{str(e)}")
                        logging.error(f"è§’è‰²çŠ¶æ€æ€»ç»“é”™è¯¯ï¼š{str(e)}", exc_info=True)
            else:
                print(f"âŒ ç¬¬ {chapter_num} ç« ç”Ÿæˆå¤±è´¥ï¼")
                break


        print("\n" + "=" * 60)
        print("ğŸ‰ å°è¯´ç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•ï¼š{os.path.abspath(filepath)}")
        print("=" * 60)
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
        for root, dirs, files in os.walk(filepath):
            for file in files:
                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, filepath)
                print(f"  - {rel_path}")
                
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}")
        logging.error(f"ç”Ÿæˆé”™è¯¯ï¼š{str(e)}", exc_info=True)


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())