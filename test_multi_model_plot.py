#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹æƒ…èŠ‚æ¶æ„ç”Ÿæˆæµ‹è¯•è„šæœ¬

è¯¥è„šæœ¬ç”¨äºæµ‹è¯•æ–°çš„å¤šæ¨¡å‹æƒ…èŠ‚æ¶æ„ç”ŸæˆåŠŸèƒ½ã€‚
å®ƒä¼šä½¿ç”¨å¤šä¸ªä¸åŒçš„AIæ¨¡å‹åŒæ—¶ç”Ÿæˆæƒ…èŠ‚æ¶æ„ï¼Œå¹¶ç”Ÿæˆå¯¹æ¯”æ–‡ä»¶ä¾›ç”¨æˆ·é€‰æ‹©ã€‚
"""

import os
import logging
from novel_generator.architecture import Novel_architecture_generate

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('multi_model_plot_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def test_multi_model_plot_generation():
    """
    æµ‹è¯•å¤šæ¨¡å‹æƒ…èŠ‚æ¶æ„ç”ŸæˆåŠŸèƒ½
    """
    print("=" * 60)
    print("ğŸš€ å¤šæ¨¡å‹æƒ…èŠ‚æ¶æ„ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®
    test_config = {
        "interface_format": "gemini",  # ä¸»è¦æ¥å£æ ¼å¼ï¼ˆç”¨äºè§’è‰²å’Œä¸–ç•Œè§‚ç”Ÿæˆï¼‰
        "api_key": "AIzaSyD36taFUaT7sv0iKwzLyuFeqZiZPoQtSnA",
        "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
        "llm_model": "gemini-2.5-pro",
        "topic": "å‡ºèº«å¹³å‡¡çš„ç”·ç”Ÿå§‹ç»ˆå€¾æ…•ç€å®¶å¢ƒä¼˜æ¸¥ã€æ°”è´¨å‡ºä¼—çš„å¥³å­©ï¼Œå´å› ä¸¤äººä¹‹é—´æ‚¬æ®Šçš„å·®è·ï¼Œè¿é è¿‘çš„æœºä¼šéƒ½å¯¥å¯¥æ— å‡ ï¼Œè¿™ä»½å¿ƒæ„åªèƒ½æ·±åŸ‹å¿ƒåº•ã€‚ä¸€æ¬¡å¶ç„¶çš„å–„ä¸¾ï¼Œä»–æ•‘åŠ©äº†ä¸€ä½é™·å…¥å›°å¢ƒçš„è€äººï¼Œæ„å¤–è·å¾—äº†è¶³ä»¥æ”¹å†™å¢ƒé‡çš„è¶…èƒ½åŠ›ã€‚å‡­å€Ÿè¿™ä»½"é¦ˆèµ "ï¼Œä»–åœ¨ä¼—å¤šå®¶å¢ƒä¼˜è¶Šã€æ¡ä»¶å‡ºä¼—çš„è¿½æ±‚è€…ä¸­è„±é¢–è€Œå‡ºï¼Œä¸ä»…æ‰“ç ´äº†æ›¾ç»çš„å·®è·å£å’ï¼Œæ›´æˆåŠŸæ‰“åŠ¨å¥³å­©ï¼Œèµ¢å¾—äº†å¥¹çš„é’çã€‚å°±åœ¨ä¸¤äººæ„Ÿæƒ…é€æ¸å‡æ¸©ï¼Œä»–ä»¥ä¸ºç»ˆäºæŠ“ä½å¹¸ç¦æ—¶ï¼Œè¶…èƒ½åŠ›å´æ¯«æ— å¾å…†åœ°çªç„¶æ¶ˆå¤±ã€‚æ›¾ç»é è¶…èƒ½åŠ›æ­å»ºçš„ä¼˜åŠ¿ç¬é—´å´©å¡Œï¼Œä»–ä¸å¾—ä¸é¢å¯¹ä¸€ä¸ªæ®‹é…·çš„é—®é¢˜ï¼šå¤±å»"å¤–æŒ‚"çš„è‡ªå·±ï¼Œè¿˜èƒ½ç•™ä½è¿™ä»½æ¥ä¹‹ä¸æ˜“çš„çˆ±æƒ…å—ï¼Ÿ",
        "genre": "éƒ½å¸‚è¨€æƒ…",
        "number_of_chapters": 50,
        "word_number": 1200,
        "filepath": "./Test_Novel_Output",
        "user_guidance": "æ•…äº‹æƒ…èŠ‚è¦ä¸°å¯Œï¼Œå¾ªåºæ¸è¿›åœ°æ¨è¿›å‰§æƒ…ã€‚å™è¿°æ‰‹æ³•å¤šæ ·åŒ–ã€‚äººç‰©çš„èƒŒæ™¯ä¸è¦ä¸€å¼€å§‹å°±å…¨ç›˜æ‰˜å‡ºï¼Œè€Œæ˜¯è¦éšç€å‰§æƒ…çš„å±•å¼€é€æ­¥æ­ç¤ºã€‚",
        "temperature": 0.7,
        "temperature_plot": 1.3,  # æƒ…èŠ‚ç”Ÿæˆä½¿ç”¨æ›´é«˜çš„åˆ›é€ æ€§
        "max_tokens": 65536,
        "timeout": 600
    }
    
    # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
    os.makedirs(test_config["filepath"], exist_ok=True)
    
    try:
        print("\nğŸ“‹ å¼€å§‹ç”Ÿæˆå°è¯´æ¶æ„ï¼ˆåŒ…å«å¤šæ¨¡å‹æƒ…èŠ‚ç”Ÿæˆï¼‰...")
        
        Novel_architecture_generate(
            interface_format=test_config["interface_format"],
            api_key=test_config["api_key"],
            base_url=test_config["base_url"],
            llm_model=test_config["llm_model"],
            topic=test_config["topic"],
            genre=test_config["genre"],
            number_of_chapters=test_config["number_of_chapters"],
            word_number=test_config["word_number"],
            filepath=test_config["filepath"],
            user_guidance=test_config["user_guidance"],
            temperature=test_config["temperature"],
            temperature_plot=test_config["temperature_plot"],
            max_tokens=test_config["max_tokens"],
            timeout=test_config["timeout"]
        )
        
        print("\nâœ… å°è¯´æ¶æ„ç”Ÿæˆå®Œæˆï¼")
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
        
        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        output_files = [
            "character_information.txt",
            "character_state.txt", 
            "world_building.txt",
            "plot_gemini-flash.txt",
            "plot_gemini-pro.txt", 
            "plot_qwen-plus.txt",
            "plot_doubao.txt",
            "plot_comparison.txt",
            "plot_default.txt",
            "Novel_architecture.txt"
        ]
        
        for filename in output_files:
            filepath = os.path.join(test_config["filepath"], filename)
            if os.path.exists(filepath):
                print(f"   âœ… {filename}")
            else:
                print(f"   âŒ {filename} (æœªç”Ÿæˆ)")
        
        print("\n" + "=" * 60)
        print("ğŸ“– ä½¿ç”¨è¯´æ˜ï¼š")
        print("=" * 60)
        print("1. æ‰“å¼€ plot_comparison.txt æ–‡ä»¶æŸ¥çœ‹å„æ¨¡å‹ç”Ÿæˆçš„æƒ…èŠ‚æ¶æ„å¯¹æ¯”")
        print("2. é€‰æ‹©æ‚¨è®¤ä¸ºæœ€ä¼˜çš„ç‰ˆæœ¬")
        print("3. å°†é€‰ä¸­çš„å†…å®¹å¤åˆ¶åˆ° plot.txt æ–‡ä»¶ä¸­")
        print("4. é‡æ–°è¿è¡Œä¸»ç”Ÿæˆæµç¨‹ä»¥ç»§ç»­åç»­æ­¥éª¤")
        print("=" * 60)
        
        # æ˜¾ç¤ºå¯¹æ¯”æ–‡ä»¶è·¯å¾„
        comparison_file = os.path.join(test_config["filepath"], "plot_comparison.txt")
        if os.path.exists(comparison_file):
            print(f"\nğŸ“‹ å¯¹æ¯”æ–‡ä»¶ä½ç½®: {comparison_file}")
        
    except Exception as e:
        logging.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")

def show_plot_comparison(filepath: str = "./Test_Novel_Output"):
    """
    æ˜¾ç¤ºæƒ…èŠ‚æ¶æ„å¯¹æ¯”ç»“æœ
    """
    comparison_file = os.path.join(filepath, "plot_comparison.txt")
    
    if not os.path.exists(comparison_file):
        print("âŒ æœªæ‰¾åˆ°å¯¹æ¯”æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå¤šæ¨¡å‹ç”Ÿæˆ")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ“– æƒ…èŠ‚æ¶æ„å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    
    with open(comparison_file, "r", encoding="utf-8") as f:
        content = f.read()
        print(content)

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_multi_model_plot_generation()
    
    # å¯é€‰ï¼šç›´æ¥æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    input("\næŒ‰å›è½¦é”®æŸ¥çœ‹å¯¹æ¯”ç»“æœ...")
    show_plot_comparison()